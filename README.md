# ğŸš€ RMHC Run-Raiser Agent: Autonomous, Brand-Safe Fundraising Communications

**Subtitle:** A Level 2 Strategic Agent for the Enterprise Agents track, powered by Gemini.

The **RMHC Run-Raiser Agent** is designed for the Enterprise Agents track of the Google Ã— Kaggle AI Agents Intensive Capstone. It automates the creation of high-quality, on-brand fundraising communications for Ronald McDonald House Charities UK (RMHC).

This project is inspired by a real fundraising journey that **raised Â£507.15 from 68 donations**, supported by milestone assets including a â€œÂ£500+ THANK YOUâ€ poster. The agent transforms live running activity and fundraising data into safe, platform-specific messaging while enforcing tone, accuracy, and charity-appropriate sensitivity.

---

## ğŸ¯ Problem, Solution, & Real-World Impact

### âŒ The Problem

Fundraisers and CSR leads face two major challenges:

* **Slow, Manual Communication Workflows:** Crafting posts for LinkedIn, Strava, and internal channels takes time. Milestones (e.g., Â£500+) need immediate amplification to sustain momentum.
* **Brand Safety Risk:** Charity communications must be empathetic, accurate, and sensitive. Manual drafting risks tone mistakes that may harm trust and brand integrity.

### âœ… The Solution: RMHC Run-Raiser Agent

A fully autonomous agent that:
* Monitors donation totals and running activity.
* Generates platform-specific messages (LinkedIn, Strava, Internal Comms).
* Performs strict **LLM-as-a-Judge** evaluation to ensure brand safety.
* Ensures every post is safe, accurate, and aligned with RMHC values.

### ğŸŒŸ Real-World Impact

The agent is validated with real fundraising data: **Â£507.15 raised, 68 donations**, and a milestone Â£500+ celebratory asset. These provide authentic, high-value demonstration scenarios, proving the agent's ability to drive fundraising momentum in an enterprise context.

---

## ğŸ§  Architecture Overview: Level 2 Strategic Problem-Solver

The RMHC Run-Raiser Agent is designed as a Level 2 autonomous system with structured reasoning, memory, and observability.

### 1ï¸âƒ£ Orchestrator (The Brain) â€“ `src/agent.py`

The agent follows a strict **7-Step Trajectory** defined in the `SYSTEM_INSTRUCTION` (Context Engineering):

1.  Retrieve memory state.
2.  Retrieve donation + activity data.
3.  Select persona + communication strategy (Formulate `PostRequest`).
4.  Generate post candidates (Gemini call).
5.  **Quality Gate: LLM-as-a-Judge** (Mandatory evaluation).
6.  Execute publish action (simulated).
7.  Update memory and close the loop.

The agent dynamically adapts messaging personas:
* **LinkedIn:** Professional, CSR-focused
* **Strava:** Motivational, athletic tone
* **Internal Comms:** Empathetic, mission-driven

### 2ï¸âƒ£ Tools (The Hands) â€“ `src/tools.py`

Seven custom tools power the agent's actions and data retrieval:

| Tool Category | Tool Name | Type | Purpose |
| :--- | :--- | :--- | :--- |
| **Retrieval (R)** | `get_activity_summary` | R | Fetches latest running data. |
| **Retrieval (R)** | `get_fundraising_summary` | R | Fetches donation totals (Â£507.15). |
| **Retrieval (R)** | `get_memory_state` | R | Fetches statistical/episodic memory. |
| **Generation (A)** | `generate_post_candidates` | A | Uses Gemini for content creation. |
| **Evaluation (A)** | `judge_post_quality` | A | **LLM-as-a-Judge** (Scores 0â€“100, rejects unsafe content). |
| **Action (A)** | `simulate_publish_post` | A | Logs the final approved post. |
| **Action (A)** | `update_memory_state` | A | Records the successful run. |

### 3ï¸âƒ£ Memory â€“ `src/memory_schema.py`

* **Statistical Memory:** Stores campaign totals, trends, and key milestones.
* **Episodic Memory:** Stores a list of previously approved posts and historical decisions.

### 4ï¸âƒ£ Observability â€“ `TrajectoryLog`

Every agent run generates and prints a structured **7-step reasoning trace** (`TrajectoryLog`). This audit trail captures: Tool calls, retrieved data, judge scores, and the final decision rationale. This provides a transparent, auditable **"Glass-Box"** agent suitable for enterprise use.

---

## ğŸ”‘ Course Concepts Demonstrated (Scoring Requirements)

| Kaggle Course Concept | Status | Implementation Detail |
| :--- | :--- | :--- |
| **LLM-Powered Agent** | âœ… | Gemini powers content generation + Judge logic. |
| **Custom Tools** | âœ… | 7 custom tools with Pydantic request/response models. |
| **Sessions & Memory** | âœ… | Episodic + statistical memory used to inform decisions. |
| **Context Engineering** | âœ… | Detailed system prompt enforces the 7-Step Trajectory. |
| **Observability** | âœ… | Full `TrajectoryLog` is generated and displayed in every execution. |
| **Agent Evaluation** | âœ… | Strict **LLM-as-a-Judge** workflow as the Quality Gate. |
| **Sequential Orchestration** | âœ… | Multi-step agent with deterministic flow (Level 2). |

**Note:** This project exceeds the required minimum of 3 core concepts.

---

## ğŸ“ Repository Structure

RMHC-Run-Raiser-Agent/ â”œâ”€â”€ src/ â”‚ â”œâ”€â”€ agent.py # Orchestration logic, SYSTEM_INSTRUCTION â”‚ â”œâ”€â”€ tools.py # All 7 custom tools (R/A/Judge) â”‚ â”œâ”€â”€ schemas.py # Pydantic I/O models, JudgeFeedback, TrajectoryLog â”‚ â”œâ”€â”€ memory_schema.py # Memory structures (Statistical/Episodic) â”‚ â””â”€â”€ demo.py # CLI execution script â”œâ”€â”€ notebooks/ â”‚ â””â”€â”€ Capstone_Codelab.ipynb # Walkthrough notebook â”œâ”€â”€ requirements.txt # Dependencies: google-genai, pydantic â””â”€â”€ README.md


## â–¶ï¸ How to Run the Demo

### Prerequisites
1.  Install dependencies:
    ```bash
    pip install -r requirements.txt
    ```
2.  Set your Gemini API key:
    ```bash
    export GEMINI_API_KEY="your_key_here"
    ```

### Execution
Run the agent demo from the root directory:
```bash
python -m src.demo

### Output Includes:

Final approved post

Full TrajectoryLog

Proof of tools â†’ memory â†’ judge â†’ publish loop

